# Functional Tests
#WIDTH: 10,14,28,38,30,44,38,10,12
#ALIGN: left,left,left,left,left,left,left,center,center
Test ID,Test Type,Test Name,Description,Pre-conditions,Test Steps,Expected Results,Priority,Status
FT-001,Unit,Workstation Power-On,Validate all 10 workstations power on and POST successfully,Hardware installed and cabled,1. Power on each workstation; 2. Verify POST completes; 3. Check BIOS settings; 4. Verify all components detected,All workstations POST successfully with correct hardware detected,High,Not Started
FT-002,Unit,GPU Detection,Validate NVIDIA RTX A6000 GPU detected in each workstation,Ubuntu installed,1. Run nvidia-smi command; 2. Verify GPU model; 3. Check GPU memory; 4. Verify driver version,RTX A6000 48GB detected with NVIDIA driver 535.x,High,Not Started
FT-003,Unit,CUDA Installation,Validate CUDA 12.2 toolkit installation and functionality,NVIDIA driver installed,1. Run nvcc --version; 2. Compile CUDA sample; 3. Execute sample program; 4. Verify GPU execution,CUDA 12.2 compiles and executes GPU code successfully,High,Not Started
FT-004,Integration,NFS Mount Connectivity,Validate PowerScale NFS mount accessible from all workstations,PowerScale configured with NFS shares,1. Mount NFS share on workstation; 2. Create test file; 3. Verify file from another workstation; 4. Check permissions,NFS shares mount successfully with correct permissions,High,Not Started
FT-005,Integration,PyTorch GPU Access,Validate PyTorch can access and utilize GPU,CUDA and PyTorch installed,1. Import torch; 2. Check cuda.is_available(); 3. Create tensor on GPU; 4. Perform matrix operation,PyTorch detects GPU and executes tensor operations on CUDA,High,Not Started
FT-006,Integration,TensorFlow GPU Access,Validate TensorFlow can access and utilize GPU,CUDA and TensorFlow installed,1. Import tensorflow; 2. List physical devices; 3. Create tensor on GPU; 4. Execute computation,TensorFlow detects GPU and executes operations on CUDA,High,Not Started
FT-007,System,Jupyter Lab Access,Validate Jupyter Lab accessible remotely via SSH tunnel,Jupyter Lab installed,1. Start Jupyter Lab; 2. Create SSH tunnel; 3. Access via browser; 4. Create and run notebook,Jupyter Lab accessible with GPU kernel available,Medium,Not Started
FT-008,System,Datadog Agent Reporting,Validate Datadog agent collects and reports GPU metrics,Datadog agent installed,1. Check agent status; 2. Verify GPU metrics in Datadog; 3. Check custom dashboards; 4. Test alert triggers,GPU utilization and temperature metrics visible in Datadog,Medium,Not Started

# Non-Functional Tests
#WIDTH: 10,14,26,38,30,48,42,10,12
#ALIGN: left,left,left,left,left,left,left,center,center
Test ID,Test Type,Test Name,Description,Pre-conditions,Test Steps,Expected Results,Priority,Status
NFT-001,Performance,GPU TFLOPS Benchmark,Validate RTX A6000 achieves rated FP32 performance,CUDA toolkit installed,1. Run NVIDIA gpu-burn for 5 minutes; 2. Record sustained TFLOPS; 3. Monitor temperatures; 4. Compare to specifications,GPU achieves 38+ TFLOPS FP32 sustained without thermal throttling,Critical,Not Started
NFT-002,Performance,Local NVMe Throughput,Validate NVMe SSD achieves 7000 MB/s read performance,Ubuntu installed with NVMe,1. Run fio sequential read test; 2. Run fio sequential write test; 3. Run 4K random IOPS test; 4. Record all metrics,Sequential read exceeds 7000 MB/s and random 4K exceeds 1M IOPS,Critical,Not Started
NFT-003,Performance,PowerScale NFS Throughput,Validate PowerScale NAS achieves 1 GB/s aggregate,PowerScale configured with 10GbE,1. Run iperf3 network baseline; 2. Run fio NFS sequential read; 3. Run concurrent streams from multiple workstations; 4. Measure aggregate,Aggregate NFS throughput exceeds 1 GB/s with 10 concurrent streams,Critical,Not Started
NFT-004,Performance,GPU Memory Bandwidth,Validate GPU memory bandwidth for large model training,CUDA toolkit installed,1. Run NVIDIA bandwidthTest; 2. Measure host-to-device transfer; 3. Measure device-to-host transfer; 4. Compare to specifications,GPU memory bandwidth exceeds 700 GB/s as per A6000 specifications,High,Not Started
NFT-005,Reliability,GPU Thermal Stability,Validate GPU maintains safe temperatures under sustained load,All systems operational,1. Run continuous GPU workload for 4 hours; 2. Monitor temperature every 5 minutes; 3. Check for thermal throttling; 4. Record max temperature,GPU temperature stays below 83C with no thermal throttling,High,Not Started
NFT-006,Security,SSH Key Authentication,Validate SSH key-based authentication for all workstations,SSH server configured,1. Generate SSH key pair; 2. Deploy public key; 3. Disable password authentication; 4. Test key-based login,SSH access works only with key authentication,High,Not Started
NFT-007,Security,User Quota Enforcement,Validate PowerScale user quotas prevent over-allocation,User quotas configured,1. Set 10TB quota for test user; 2. Attempt to write 11TB; 3. Verify quota error; 4. Check admin override,Storage quota enforced at 10TB limit with appropriate error message,Medium,Not Started

# User Acceptance Tests
#WIDTH: 10,14,30,38,30,48,42,10,12
#ALIGN: left,left,left,left,left,left,left,center,center
Test ID,Test Type,Test Name,Description,Pre-conditions,Test Steps,Expected Results,Priority,Status
UAT-001,Business Process,ResNet Training Workflow,Validate end-to-end ResNet-152 training on ImageNet subset,PyTorch and sample dataset ready,1. Load ImageNet subset from PowerScale; 2. Initialize ResNet-152 model; 3. Train for 10 epochs; 4. Save checkpoint to PowerScale,Training completes in under 2 hours with 75%+ validation accuracy,High,Not Started
UAT-002,Business Process,Multi-User Concurrent Training,Validate 5 data scientists can train simultaneously,All workstations operational,1. Start training job on 5 workstations; 2. Monitor GPU utilization on each; 3. Check PowerScale load; 4. Verify no interference,All 5 training jobs complete without resource contention or errors,High,Not Started
UAT-003,Business Process,Dataset Transfer from Cloud,Validate AWS S3 to PowerScale migration workflow,AWS CLI configured,1. Initiate S3 sync to PowerScale; 2. Monitor transfer speed; 3. Verify file integrity with checksums; 4. Compare transfer time,5TB dataset transfers in under 90 minutes with 100% integrity,High,Not Started
UAT-004,User Interface,Jupyter Notebook Workflow,Validate data scientist can complete typical notebook workflow,Jupyter Lab accessible,1. Create new notebook; 2. Import PyTorch and load data; 3. Train simple model; 4. Visualize results; 5. Save notebook,Complete workflow executes with GPU acceleration visible in notebook,Medium,Not Started
UAT-005,User Interface,VS Code Remote Development,Validate VS Code Remote-SSH workflow for development,VS Code with Remote-SSH extension,1. Connect to workstation via Remote-SSH; 2. Open project folder; 3. Run Python script with GPU; 4. Debug with breakpoints,VS Code provides full IDE experience with GPU debugging support,Medium,Not Started
UAT-006,Business Process,Model Checkpoint Recovery,Validate ability to resume training from saved checkpoint,Previous training checkpoint saved,1. Load saved checkpoint from PowerScale; 2. Resume training; 3. Verify loss continuation; 4. Complete training,Training resumes from checkpoint without data loss or retraining,Medium,Not Started
