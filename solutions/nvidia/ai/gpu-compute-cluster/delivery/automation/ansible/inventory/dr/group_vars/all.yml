#------------------------------------------------------------------------------
# NVIDIA GPU Compute Cluster - DR Environment Variables
#------------------------------------------------------------------------------
# Generated from configuration.csv - DR column
# To regenerate: python generate-ansible-vars.py --env dr
# DO NOT EDIT - Changes will be overwritten on regeneration
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# Project Configuration
#------------------------------------------------------------------------------
solution:
  name: nvidia-gpu-compute-cluster
  abbr: gpucc
  provider_name: nvidia
  category_name: ai

#------------------------------------------------------------------------------
# Cluster Configuration
#------------------------------------------------------------------------------
cluster:
  name: gpu-cluster-dr
  domain: gpu-dr.client.local
  timezone: UTC

#------------------------------------------------------------------------------
# Hardware Configuration
#------------------------------------------------------------------------------
hardware:
  gpu_node_count: 16
  gpu_model: A100 80GB PCIe
  gpu_count_per_node: 4
  gpu_memory_gb: 80
  cpu_model: AMD EPYC 7763
  cpu_cores_per_node: 128
  system_ram_gb: 1024
  nvme_storage_tb: 7.68
  server_model: Custom OEM

#------------------------------------------------------------------------------
# Network Configuration
#------------------------------------------------------------------------------
network:
  fabric_type: RoCE v2
  fabric_speed_gbps: 100
  fabric_switch_model: NVIDIA SN4600
  fabric_switch_count: 2
  management_vlan: 120
  management_cidr: 10.120.0.0/24
  management_gateway: 10.120.0.1
  gpu_fabric_vlan: 220
  gpu_fabric_cidr: 10.220.0.0/24
  bmc_vlan: 121
  bmc_cidr: 10.121.0.0/24

#------------------------------------------------------------------------------
# Storage Configuration
#------------------------------------------------------------------------------
storage:
  shared_type: NFS
  shared_server: storage-dr.client.local
  shared_export: /export/gpu-dr
  shared_mount: /shared
  shared_capacity_tb: 100
  dataset_path: /shared/datasets
  model_path: /shared/models
  scratch_path: /scratch

#------------------------------------------------------------------------------
# Slurm Workload Management
#------------------------------------------------------------------------------
slurm:
  version: "23.11"
  controller_ip: 10.120.0.10
  controller_backup_ip: 10.120.0.11
  partition_gpu: gpu-a100
  partition_cpu: cpu-only
  max_job_time_hours: 72
  default_cpus_per_gpu: 32
  gres_config: "gpu:a100:4"
  accounting_db: slurm_acct_db
  fairshare_enabled: true

#------------------------------------------------------------------------------
# Software Stack
#------------------------------------------------------------------------------
software:
  nvidia_driver_version: "550.54.14"
  cuda_version: "12.4"
  cudnn_version: "9.0.0"
  nccl_version: "2.21.5"
  os_version: Ubuntu 22.04
  python_version: "3.11"

#------------------------------------------------------------------------------
# Containers
#------------------------------------------------------------------------------
containers:
  ngc_registry: nvcr.io
  pytorch_tag: "24.08-py3"
  tensorflow_tag: "24.08-tf2-py3"
  rapids_tag: "24.08-cuda12.4-py3.11"
  triton_tag: "24.08-py3"

#------------------------------------------------------------------------------
# Monitoring Configuration
#------------------------------------------------------------------------------
monitoring:
  prometheus_enabled: true
  prometheus_server_ip: 10.120.0.40
  grafana_enabled: true
  grafana_server_ip: 10.120.0.41
  dcgm_exporter_enabled: true
  gpu_util_alert_threshold: 95
  gpu_temp_alert_threshold: 83
  gpu_memory_alert_threshold: 95
  syslog_server: 10.120.0.42
  syslog_port: 514

#------------------------------------------------------------------------------
# Security Configuration
#------------------------------------------------------------------------------
security:
  ldap_enabled: true
  ldap_server_primary: 10.120.2.10
  ldap_server_secondary: 10.120.2.11
  ldap_base_dn: "DC=client,DC=local"
  ldap_bind_user: svc_gpu_ldap_dr
  ssh_key_auth_only: true
  firewall_enabled: true
  root_ssh_enabled: false

#------------------------------------------------------------------------------
# Operations Configuration
#------------------------------------------------------------------------------
operations:
  backup_enabled: true
  backup_retention_days: 30
  backup_schedule: "0 2 * * *"
  maintenance_window: "Sunday 02:00-06:00 UTC"
  ntp_server_primary: 10.120.4.10
  ntp_server_secondary: 10.120.4.11
  dns_server_primary: 10.120.5.10
  dns_server_secondary: 10.120.5.11

#------------------------------------------------------------------------------
# Support Configuration
#------------------------------------------------------------------------------
support:
  nvidia_support_level: Enterprise
  support_response_sla_hr: 4
  support_email: gpu-support@client.local

#------------------------------------------------------------------------------
# DR Configuration
#------------------------------------------------------------------------------
dr:
  enabled: true
  replication_enabled: true
  rpo_hours: 24
  rto_hours: 4
