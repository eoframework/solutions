#WIDTH: 28,16,14,24,40,10,12,30,16,18,24,35,12
#ALIGN: left,left,center,left,left,center,left,left,center,left,left,left,center
Parameter Name,Category,Environment,Default Value,Description,Required,Data Type,Validation Rules,Security Level,Owner Team,Dependencies,Notes,Last Updated
DGX_CLUSTER_NAME,Application,All,dgx-superpod-prod,DGX SuperPOD cluster identifier,Yes,String,Max 30 alphanumeric chars,Public,AI Infrastructure,None,Used in Slurm and monitoring,[DATE]
DGX_NODE_COUNT,Hardware,All,8,Number of DGX H100 nodes in SuperPOD,Yes,Integer,8-256,Public,Hardware Team,Power and cooling,Phase 1 deployment,[DATE]
DGX_NODE_MODEL,Hardware,All,DGX H100,DGX system model specification,Yes,String,Valid DGX model identifier,Public,Hardware Team,Performance requirements,Latest H100 generation,[DATE]
GPU_COUNT_PER_NODE,Hardware,All,8,Number of H100 GPUs per DGX node,Yes,Integer,8,Public,Hardware Team,DGX_NODE_MODEL,Fixed for H100 platform,[DATE]
GPU_MODEL,Hardware,All,H100 80GB SXM,GPU model and memory specification,Yes,String,Valid NVIDIA GPU model,Public,AI Team,Workload requirements,80GB HBM3 memory,[DATE]
GPU_MEMORY_GB,Hardware,All,80,GPU HBM3 memory in GB per GPU,Yes,Integer,80,Public,AI Team,Model size requirements,640 GB per node total,[DATE]
TOTAL_GPU_COUNT,Hardware,All,64,Total GPUs across all DGX nodes,Yes,Integer,Calculated,Public,AI Team,GPU_COUNT_PER_NODE,8 nodes x 8 GPUs,[DATE]
SYSTEM_RAM_GB,Hardware,All,2048,System RAM per DGX node in GB,Yes,Integer,2048,Public,Hardware Team,Data preprocessing,DDR5 memory,[DATE]
NVME_STORAGE_TB,Storage,All,30,Local NVMe storage per node in TB,Yes,Integer,30,Public,Storage Team,Checkpoint storage,High-speed scratch,[DATE]
INFINIBAND_SPEED,Network,All,400,InfiniBand port speed in Gbps,Yes,Integer,400,Public,Network Team,NDR InfiniBand,Quantum-2 fabric,[DATE]
INFINIBAND_PORTS_PER_NODE,Network,All,8,InfiniBand ports per DGX node,Yes,Integer,8,Public,Network Team,Fabric topology,Full mesh capable,[DATE]
INFINIBAND_SWITCH_MODEL,Network,All,QM9700,InfiniBand switch model,Yes,String,Valid NVIDIA IB switch,Public,Network Team,Port density,40-port NDR switches,[DATE]
INFINIBAND_SWITCH_COUNT,Network,All,4,Number of InfiniBand switches,Yes,Integer,4-8,Public,Network Team,Network topology,Leaf-spine architecture,[DATE]
AGGREGATE_IB_BANDWIDTH_TBPS,Network,All,3.2,Aggregate InfiniBand bandwidth in Tbps,Yes,Float,Calculated,Public,Network Team,IB port count,Bisection bandwidth,[DATE]
STORAGE_SYSTEM,Storage,All,Base Command 1PB,Shared storage platform,Yes,String,Valid storage platform,Public,Storage Team,Dataset storage,NVMe all-flash,[DATE]
SHARED_STORAGE_PB,Storage,All,1.0,Shared storage capacity in PB,Yes,Float,0.5-10.0,Public,Storage Team,Dataset requirements,Expandable,[DATE]
STORAGE_THROUGHPUT_GBS,Storage,All,14,Target storage throughput in GB/s,Yes,Integer,14-50,Public,Storage Team,Training I/O,Sustained read/write,[DATE]
PARALLEL_FILESYSTEM,Storage,All,Lustre,Parallel filesystem for AI workloads,Yes,String,Lustre|GPFS|WekaFS,Public,Storage Team,Performance optimization,High-performance I/O,[DATE]
SLURM_VERSION,Workload Mgmt,All,23.02.6,Slurm workload manager version,Yes,String,Valid Slurm version,Public,AI Operations,Job scheduling,Latest stable,[DATE]
SLURM_PARTITION_GPU,Workload Mgmt,All,gpu-h100,Primary GPU partition name,Yes,String,Valid partition name,Public,AI Operations,Resource allocation,Default partition,[DATE]
SLURM_MAX_JOB_TIME,Workload Mgmt,All,168:00:00,Maximum job runtime (7 days),Yes,String,Valid time format,Public,AI Operations,Resource planning,Long training support,[DATE]
SLURM_DEFAULT_CPUS_PER_GPU,Workload Mgmt,All,16,Default CPU cores per GPU allocation,Yes,Integer,8-32,Public,AI Operations,Resource allocation,Balanced ratio,[DATE]
SLURM_GRES_CONFIG,Workload Mgmt,All,gpu:h100:8,GRES configuration per node,Yes,String,Valid GRES format,Public,AI Operations,GPU scheduling,8 GPUs per node,[DATE]
CUDA_VERSION,Software Stack,All,12.2,CUDA toolkit version,Yes,String,Valid CUDA version,Public,Software Team,GPU compatibility,Latest stable,[DATE]
CUDNN_VERSION,Software Stack,All,8.9.7,cuDNN library version,Yes,String,Valid cuDNN version,Public,Software Team,CUDA_VERSION,Deep learning ops,[DATE]
NCCL_VERSION,Software Stack,All,2.19.3,NCCL communication library version,Yes,String,Valid NCCL version,Public,Software Team,Multi-GPU comm,Latest performance,[DATE]
NVIDIA_DRIVER_VERSION,Software Stack,All,535.154.05,NVIDIA GPU driver version,Yes,String,Valid driver version,Public,Software Team,CUDA_VERSION,Production driver,[DATE]
DGX_OS_VERSION,Software Stack,All,6.0.0,DGX OS version,Yes,String,Valid DGX OS version,Public,Software Team,Driver support,Ubuntu-based,[DATE]
NGC_CONTAINER_REGISTRY,AI Frameworks,All,nvcr.io,NVIDIA NGC container registry URL,Yes,String,Valid registry URL,Public,AI Team,Container deployment,Official containers,[DATE]
PYTORCH_NGC_TAG,AI Frameworks,All,24.01-py3,PyTorch NGC container tag,Yes,String,Valid container tag,Public,AI Team,Model development,Latest optimized,[DATE]
TENSORFLOW_NGC_TAG,AI Frameworks,All,24.01-tf2-py3,TensorFlow NGC container tag,Yes,String,Valid container tag,Public,AI Team,Model development,TF 2.x optimized,[DATE]
JAX_NGC_TAG,AI Frameworks,All,24.01-py3,JAX NGC container tag,Yes,String,Valid container tag,Public,AI Team,Model development,XLA backend,[DATE]
TRITON_NGC_TAG,AI Frameworks,All,24.01-py3,Triton Inference Server tag,Yes,String,Valid container tag,Public,AI Team,Model serving,Inference optimization,[DATE]
JUPYTER_ENABLED,Development,All,true,Enable JupyterHub for interactive dev,Yes,Boolean,true|false,Public,AI Team,Data science workflow,GPU-enabled notebooks,[DATE]
TENSORBOARD_ENABLED,Development,All,true,Enable TensorBoard visualization,Yes,Boolean,true|false,Public,AI Team,Training monitoring,Metrics visualization,[DATE]
MLFLOW_TRACKING_ENABLED,MLOps,All,true,Enable MLflow experiment tracking,Yes,Boolean,true|false,Public,MLOps Team,Model lifecycle,Experiment management,[DATE]
MODEL_STORAGE_PATH,Storage,All,/shared/models,Shared path for trained models,Yes,String,Valid Unix path,Public,AI Team,Model deployment,Cross-node access,[DATE]
DATASET_STORAGE_PATH,Storage,All,/shared/datasets,Shared path for training datasets,Yes,String,Valid Unix path,Public,AI Team,Data access,High-performance,[DATE]
CHECKPOINT_STORAGE_PATH,Storage,All,/shared/checkpoints,Shared path for training checkpoints,Yes,String,Valid Unix path,Public,AI Team,Training recovery,Fault tolerance,[DATE]
MONITORING_STACK,Monitoring,All,Prometheus + Grafana,Primary monitoring platform,Yes,String,Valid monitoring stack,Public,Operations,GPU monitoring,DCGM integration,[DATE]
DCGM_EXPORTER_ENABLED,Monitoring,All,true,Enable NVIDIA DCGM metrics export,Yes,Boolean,true|false,Public,Operations,GPU monitoring,Real-time metrics,[DATE]
GPU_UTIL_ALERT_THRESHOLD,Monitoring,All,95,GPU utilization alert threshold %,Yes,Integer,80-99,Public,Operations,Resource optimization,High util alert,[DATE]
GPU_TEMP_ALERT_THRESHOLD,Monitoring,All,83,GPU temperature alert threshold C,Yes,Integer,80-85,Public,Operations,Thermal management,Throttle prevention,[DATE]
GPU_MEMORY_ALERT_THRESHOLD,Monitoring,All,90,GPU memory usage alert threshold %,Yes,Integer,80-95,Public,Operations,Memory management,OOM prevention,[DATE]
LDAP_ENABLED,Security,All,true,Enable LDAP user authentication,Yes,Boolean,true|false,Confidential,Security Team,User management,Central auth,[DATE]
LDAP_SERVER_URL,Security,All,[ldap-server-url],LDAP server endpoint,Yes,String,Valid LDAP URL,Secret,Security Team,Directory service,AD integration,[DATE]
LDAP_BASE_DN,Security,All,[ldap-base-dn],LDAP base distinguished name,Yes,String,Valid DN format,Confidential,Security Team,User search,Organization unit,[DATE]
SSH_KEY_AUTH_ONLY,Security,All,true,Enforce SSH key authentication only,Yes,Boolean,true|false,Public,Security Team,Secure access,Disable passwords,[DATE]
FIREWALL_POLICY,Security,All,restrictive,Network firewall configuration,Yes,String,restrictive|standard,Confidential,Security Team,Network security,Minimal surface,[DATE]
BACKUP_RETENTION_DAYS,Operations,All,90,Backup retention period in days,Yes,Integer,30-365,Public,Operations,Data protection,Compliance req,[DATE]
BACKUP_SCHEDULE,Operations,All,0 2 * * *,Daily backup schedule (cron),Yes,String,Valid cron expression,Public,Operations,Backup strategy,2 AM UTC,[DATE]
MAINTENANCE_WINDOW,Operations,All,Sunday 02:00-06:00 UTC,Weekly maintenance window,Yes,String,Valid time range,Public,Operations,Minimal disruption,Low-usage period,[DATE]
NVIDIA_SUPPORT_LEVEL,Support,All,Enterprise,NVIDIA support contract level,Yes,String,Enterprise|Priority,Confidential,Support Team,Critical workloads,24x7 support,[DATE]
SUPPORT_RESPONSE_SLA_HR,Support,All,4,Critical issue response SLA in hours,Yes,Integer,4-24,Public,Support Team,Incident response,Hardware issues,[DATE]
DR_ENABLED,Operations,Production,false,Disaster recovery enabled,Yes,Boolean,true|false,Public,DR Team,Business continuity,Phase 2 option,[DATE]
POWER_CAPACITY_KW,Facilities,All,500,Total power capacity in kW,Yes,Integer,400-1000,Public,Facilities Team,Infrastructure,Per 8 DGX nodes,[DATE]
COOLING_CAPACITY_KW,Facilities,All,500,Cooling capacity in kW,Yes,Integer,400-1000,Public,Facilities Team,Thermal management,Match power load,[DATE]
