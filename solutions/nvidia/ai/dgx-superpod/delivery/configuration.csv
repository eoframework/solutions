Parameter Name,Category,Environment,Default Value,Description,Required,Data Type,Validation Rules,Security Level,Owner Team,Dependencies,Notes,Last Updated
DGX_SOLUTION_NAME,Application,All,NVIDIA DGX SuperPod,NVIDIA DGX SuperPod solution identifier,Yes,String,Max 50 characters,Public,AI Infrastructure,None,Used in cluster monitoring and job scheduling,[DATE]
DGX_SUPERPOD_VERSION,Application,All,3.1.0,Current DGX SuperPod software version,Yes,String,Semantic versioning format,Public,AI Infrastructure,None,Aligned with NVIDIA release schedule,[DATE]
DGX_NODE_COUNT,Hardware,All,20,Number of DGX nodes in SuperPod,Yes,Integer,8-256,Public,Hardware Team,Power and cooling,Plan for growth and redundancy,[DATE]
DGX_NODE_MODEL,Hardware,All,DGX H100,DGX node model specification,Yes,String,Valid DGX model,Public,Hardware Team,Performance requirements,Latest H100 generation,[DATE]
GPU_COUNT_PER_NODE,Hardware,All,8,Number of GPUs per DGX node,Yes,Integer,4-8,Public,Hardware Team,DGX_NODE_MODEL,H100 standard configuration,[DATE]
GPU_MODEL_TYPE,Hardware,All,H100 80GB,GPU model and memory specification,Yes,String,Valid NVIDIA GPU model,Public,AI Team,Workload requirements,Latest H100 architecture,[DATE]
GPU_MEMORY_PER_NODE_GB,Hardware,All,640,Total GPU memory per node in GB,Yes,Integer,320-640,Public,AI Team,Model size requirements,8x 80GB H100 GPUs,[DATE]
SYSTEM_MEMORY_PER_NODE_GB,Hardware,All,2048,System RAM per DGX node in GB,Yes,Integer,1024-2048,Public,Hardware Team,Data preprocessing,High memory for large datasets,[DATE]
NVME_STORAGE_PER_NODE_TB,Storage,All,30,NVMe storage per DGX node in TB,Yes,Integer,15-30,Public,Storage Team,Checkpoint storage,High-speed local storage,[DATE]
INFINIBAND_FABRIC_TYPE,Network,All,NDR400,InfiniBand fabric specification,Yes,String,Valid IB fabric type,Public,Network Team,Inter-node communication,400Gb/s NDR for optimal performance,[DATE]
INFINIBAND_SWITCH_COUNT,Network,All,4,Number of InfiniBand switches,Yes,Integer,2-8,Public,Network Team,Network topology,Leaf-spine architecture,[DATE]
INFINIBAND_SWITCH_MODEL,Network,All,QM9700,InfiniBand switch model,Yes,String,Valid IB switch model,Public,Network Team,Port density,40-port 400Gb/s switches,[DATE]
ETHERNET_FABRIC_TYPE,Network,All,100GbE,Ethernet fabric for management,Yes,String,Valid Ethernet speed,Public,Network Team,Management traffic,Separate from IB fabric,[DATE]
STORAGE_SYSTEM_TYPE,Storage,All,NetApp AFF A900,Shared storage system type,Yes,String,Valid storage platform,Public,Storage Team,Dataset storage,High-performance NFS/parallel FS,[DATE]
SHARED_STORAGE_CAPACITY_PB,Storage,All,2.0,Shared storage capacity in petabytes,Yes,Float,1.0-10.0,Public,Storage Team,Dataset requirements,Plan for dataset growth,[DATE]
PARALLEL_FILESYSTEM,Storage,All,WekaFS,Parallel filesystem for AI workloads,Yes,String,Valid parallel FS,Public,Storage Team,Performance optimization,Optimized for AI I/O patterns,[DATE]
SLURM_VERSION,Workload Management,All,22.05.8,Slurm workload manager version,Yes,String,Valid Slurm version,Public,AI Operations,Job scheduling,Latest stable release,[DATE]
SLURM_PARTITION_CONFIG,Workload Management,All,gpu-h100,Primary Slurm partition name,Yes,String,Valid partition name,Public,AI Operations,Resource allocation,GPU-optimized partition,[DATE]
SLURM_MAX_JOB_TIME,Workload Management,All,168:00:00,Maximum job runtime (hours:min:sec),Yes,String,Valid time format,Public,AI Operations,Resource planning,7 days maximum,[DATE]
SLURM_DEFAULT_CPUS_PER_GPU,Workload Management,All,16,Default CPU cores per GPU,Yes,Integer,8-32,Public,AI Operations,Resource allocation,Balanced CPU-GPU ratio,[DATE]
CUDA_VERSION,Software Stack,All,12.2,CUDA toolkit version,Yes,String,Valid CUDA version,Public,Software Team,GPU compatibility,Latest stable CUDA,[DATE]
CUDNN_VERSION,Software Stack,All,8.9.7,cuDNN library version,Yes,String,Valid cuDNN version,Public,Software Team,CUDA_VERSION,Deep learning optimization,[DATE]
NCCL_VERSION,Software Stack,All,2.18.5,NCCL communication library version,Yes,String,Valid NCCL version,Public,Software Team,Multi-GPU communication,Latest performance optimizations,[DATE]
NVIDIA_DRIVER_VERSION,Software Stack,All,535.104.12,NVIDIA GPU driver version,Yes,String,Valid driver version,Public,Software Team,CUDA_VERSION,Latest production driver,[DATE]
NGC_CONTAINER_REGISTRY,AI Frameworks,All,nvcr.io,NVIDIA NGC container registry,Yes,String,Valid registry URL,Public,AI Team,Container deployment,Official NVIDIA containers,[DATE]
PYTORCH_VERSION,AI Frameworks,All,2.1.0,PyTorch framework version,Yes,String,Valid PyTorch version,Public,AI Team,Model development,NGC container version,[DATE]
TENSORFLOW_VERSION,AI Frameworks,All,2.13.0,TensorFlow framework version,Yes,String,Valid TF version,Public,AI Team,Model development,NGC container version,[DATE]
TRITON_INFERENCE_VERSION,AI Frameworks,All,23.08,NVIDIA Triton inference server version,Yes,String,Valid Triton version,Public,AI Team,Model serving,Latest inference optimizations,[DATE]
HOROVOD_VERSION,AI Frameworks,All,0.28.1,Horovod distributed training version,Yes,String,Valid Horovod version,Public,AI Team,Distributed training,Multi-node training framework,[DATE]
JUPYTER_LAB_ENABLED,Development Tools,All,true,Enable JupyterLab for development,Yes,Boolean,true|false,Public,AI Team,Data science workflow,Interactive development environment,[DATE]
TENSORBOARD_ENABLED,Development Tools,All,true,Enable TensorBoard for visualization,Yes,Boolean,true|false,Public,AI Team,Training monitoring,Training metrics visualization,[DATE]
MLFLOW_TRACKING_ENABLED,MLOps,All,true,Enable MLflow experiment tracking,Yes,Boolean,true|false,Public,MLOps Team,Model lifecycle,Experiment management,[DATE]
MLFLOW_MODEL_REGISTRY,MLOps,All,enabled,MLflow model registry configuration,Yes,String,enabled|disabled,Public,MLOps Team,Model versioning,Centralized model storage,[DATE]
KUBEFLOW_ENABLED,MLOps,All,false,Enable Kubeflow for ML pipelines,No,Boolean,true|false,Public,MLOps Team,Pipeline orchestration,Container-based ML workflows,[DATE]
MODEL_STORAGE_PATH,Storage,All,/shared/models,Shared path for trained models,Yes,String,Valid Unix path,Public,AI Team,Model deployment,Accessible from all nodes,[DATE]
DATASET_STORAGE_PATH,Storage,All,/shared/datasets,Shared path for training datasets,Yes,String,Valid Unix path,Public,AI Team,Data access,High-performance storage,[DATE]
CHECKPOINT_STORAGE_PATH,Storage,All,/shared/checkpoints,Shared path for training checkpoints,Yes,String,Valid Unix path,Public,AI Team,Training recovery,Fault tolerance,[DATE]
MONITORING_SYSTEM,Monitoring,All,Prometheus + Grafana,Primary monitoring platform,Yes,String,Valid monitoring stack,Public,Operations,GPU utilization tracking,AI-optimized dashboards,[DATE]
DCGM_EXPORTER_ENABLED,Monitoring,All,true,Enable NVIDIA DCGM metrics,Yes,Boolean,true|false,Public,Operations,GPU monitoring,Real-time GPU metrics,[DATE]
NVIDIA_SMI_EXPORTER_ENABLED,Monitoring,All,true,Enable nvidia-smi metrics export,Yes,Boolean,true|false,Public,Operations,Basic GPU monitoring,Legacy compatibility,[DATE]
GPU_UTILIZATION_ALERT_THRESHOLD,Monitoring,All,95,GPU utilization alert threshold %,Yes,Integer,80-99,Public,Operations,Resource optimization,High utilization alert,[DATE]
GPU_MEMORY_ALERT_THRESHOLD,Monitoring,All,90,GPU memory alert threshold %,Yes,Integer,80-95,Public,Operations,Memory management,Prevent OOM errors,[DATE]
TEMPERATURE_ALERT_THRESHOLD,Monitoring,All,83,GPU temperature alert threshold Â°C,Yes,Integer,80-85,Public,Operations,Thermal management,Prevent thermal throttling,[DATE]
POWER_CONSUMPTION_MONITORING,Monitoring,All,enabled,Monitor GPU power consumption,Yes,String,enabled|disabled,Public,Operations,Power management,Energy efficiency tracking,[DATE]
CONTAINER_RUNTIME,Container Platform,All,Docker,Container runtime platform,Yes,String,Docker|Podman|containerd,Public,Platform Team,NVIDIA container support,GPU container runtime,[DATE]
CONTAINER_REGISTRY,Container Platform,All,[internal-registry],Internal container registry,Yes,String,Valid registry URL,Confidential,Platform Team,Image management,Private model containers,[DATE]
LDAP_AUTHENTICATION,Security,All,enabled,LDAP user authentication,Yes,String,enabled|disabled,Confidential,Security Team,User management,Centralized authentication,[DATE]
LDAP_SERVER_URL,Security,All,[ldap-server],LDAP server endpoint,Yes,String,Valid LDAP URL,Secret,Security Team,Directory service,Active Directory integration,[DATE]
SSH_KEY_AUTHENTICATION,Security,All,required,SSH key authentication requirement,Yes,String,required|optional|disabled,Public,Security Team,Secure access,Disable password auth,[DATE]
FIREWALL_RULES,Security,All,restrictive,Network firewall configuration,Yes,String,restrictive|standard|permissive,Confidential,Security Team,Network security,Minimal attack surface,[DATE]
BACKUP_STRATEGY,Operations,All,incremental,Backup strategy for critical data,Yes,String,full|incremental|differential,Public,Operations,Data protection,Model and checkpoint backup,[DATE]
BACKUP_RETENTION_DAYS,Operations,All,90,Backup retention period in days,Yes,Integer,30-365,Public,Operations,Storage planning,Compliance requirements,[DATE]
MAINTENANCE_WINDOW,Operations,All,Sunday 02:00-06:00 UTC,Weekly maintenance window,Yes,String,Valid time range,Public,Operations,Minimal disruption,Low-usage period,[DATE]
NVIDIA_SUPPORT_CONTRACT,Support,All,Enterprise Support,NVIDIA support contract level,Yes,String,Valid contract type,Confidential,Support Team,Critical workloads,24x7 enterprise support,[DATE]
DGX_EXPERT_ASSISTANCE,Support,All,enabled,DGX Expert Assistance program,Yes,String,enabled|disabled,Public,Support Team,Performance optimization,Proactive support,[DATE]
DISASTER_RECOVERY_ENABLED,Operations,Production,true,Enable disaster recovery planning,Yes,Boolean,true|false,Public,DR Team,Business continuity,Multi-site resilience,[DATE]
MODEL_CHECKPOINTING_INTERVAL,AI Training,All,3600,Model checkpoint interval in seconds,Yes,Integer,300-7200,Public,AI Team,Training recovery,Balance overhead and recovery,[DATE]
DISTRIBUTED_TRAINING_BACKEND,AI Training,All,nccl,Backend for distributed training,Yes,String,nccl|mpi|gloo,Public,AI Team,Multi-node training,Optimal for NVIDIA GPUs,[DATE]
AUTO_SCALING_ENABLED,Resource Management,All,false,Enable automatic resource scaling,No,Boolean,true|false,Public,Operations,Workload management,Future capability,[DATE]
